{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IS-Saja/StoryTeller-AI-Models/blob/main/Stort_Teller_AI_Models_Simple_Pipeline_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XTYmNjVbbdN4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a115182-b838-4b32-954b-3b539b2bd62f",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Explanation**\n",
        " In this section we are using the Hugging Face Transformers library to create a text-to-text generation pipeline using the pipeline function. We are specifically loading a model called \"maldv/badger-writer-llama-3-8b\", which is suited for generating creative text, such as storytelling or narrative generation.\n",
        "\n",
        "### **Key Steps**\n",
        "\n",
        "1.   **Importing the pipeline:** We first import the pipeline function from Hugging Face's Transformers library.\n",
        "2.   **Loading the Model:** We specify the model (maldv/badger-writer-llama-3-8b) and task (text2text-generation) in the pipeline. This model is designed to generate text based on input prompts, making it ideal for tasks like storytelling or long-form text generation.\n",
        "3. **Verifying the Loaded Model:** We print the pipeline to confirm that it has been successfully loaded and is ready for use."
      ],
      "metadata": {
        "id": "8Y7KR-iVwpwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# List of models to use\n",
        "models = [\n",
        "    'gpt2',\n",
        "    'gpt2-large'\n",
        "]"
      ],
      "metadata": {
        "id": "oMegA_yQXvQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-a8l0IXxbqOy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33710012-2951-4ecc-cc86-b10a19fa33af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ],
      "source": [
        "# The prompt for generating stories\n",
        "prompt = \"\"\"\n",
        "One day, King Eldran was visited by a wise old wizard named Zephyr, who warned him of a great danger that threatened the kingdom. Meanwhile, in a distant village, a young boy named Eldric and his friends discovered a mysterious box deep in the forest. The box, carved with ancient runes and glowing with a strange light, had no key, and no one knew its origins. As the danger loomed over the kingdom, Eldric's discovery would change everything.\n",
        "\"\"\"\n",
        "\n",
        "# Dictionary to store the results\n",
        "stories = {}\n",
        "\n",
        "# Generate text for each model\n",
        "for model_name in models:\n",
        "    try:\n",
        "        generator = pipeline(\"text-generation\", model=model_name)\n",
        "        story = generator(prompt, max_length=230, no_repeat_ngram_size=3, temperature=0.8, top_p=0.95)\n",
        "        stories[model_name] = story[0]['generated_text']\n",
        "    except Exception as e:\n",
        "        stories[model_name] = f\"Error generating story: {str(e)}\"\n",
        "\n",
        "# Print the stories dictionary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Explanation:**\n",
        "\n",
        "In this part of the code, we generate a detailed story using the Hugging Face text-to-text pipeline. The prompt provides a scenario in which King Eldran is warned of a great danger, while a young boy named Eldric stumbles upon a mysterious box in a distant village. The model will continue this story based on the provided input.\n",
        "\n",
        "###**Key Steps:**\n",
        "1. Defining the Prompt:\n",
        "The prompt describes two interconnected events—a wizard’s warning to a king and a young boy's discovery of a strange object in the forest. This serves as the starting point for the AI-generated story.\n",
        "2. Text Generation Parameters:\n",
        "* max_length=230: Limits the generated text to a maximum of 230\n",
        "tokens (words or word pieces).\n",
        "* no_repeat_ngram_size=3: Prevents the model from repeating any sequence of three consecutive words, ensuring variety in the output.\n",
        "* temperature=0.8: Adjusts the model's creativity. A higher temperature allows for more randomness and creative outputs.\n",
        "* top_p=0.95: Uses nucleus sampling to select the next word from the top 95% of the most probable words, encouraging diversity in the generated text.\n",
        "\n",
        "\n",
        "###**Output:**\n",
        "The generated text is a continuation of the given prompt, adding more details and extending the story beyond the initial setup. The final text is printed out for viewing."
      ],
      "metadata": {
        "id": "UinZugo0ychf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for model_name, story in stories.items():\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"Generated Story: {story}\\n\")"
      ],
      "metadata": {
        "id": "hXK6UurN76JM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219d8391-a94c-41ab-cc21-6c684ef58096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: gpt2\n",
            "Generated Story: \n",
            "One day, King Eldran was visited by a wise old wizard named Zephyr, who warned him of a great danger that threatened the kingdom. Meanwhile, in a distant village, a young boy named Eldric and his friends discovered a mysterious box deep in the forest. The box, carved with ancient runes and glowing with a strange light, had no key, and no one knew its origins. As the danger loomed over the kingdom, Eldric's discovery would change everything.\n",
            "\n",
            "The young boy's fate was sealed by a curse that he had been blessed with. He was given a magical shield by the witch, and he had the power to protect himself and others. After a while, he was able to use it to take on the power of the cursed box, and then to bring the curse to his own home.\n",
            "...\n",
            "\n",
            "When I read the rest of the first volume, I was deeply moved by the story, and I have enjoyed it many times. There are numerous chapters in which the characters and the plots are made explicit, and many scenes from the books that I have never seen in my life\n",
            "\n",
            "Model: gpt2-large\n",
            "Generated Story: \n",
            "One day, King Eldran was visited by a wise old wizard named Zephyr, who warned him of a great danger that threatened the kingdom. Meanwhile, in a distant village, a young boy named Eldric and his friends discovered a mysterious box deep in the forest. The box, carved with ancient runes and glowing with a strange light, had no key, and no one knew its origins. As the danger loomed over the kingdom, Eldric's discovery would change everything.\n",
            "\n",
            "A great adventure has begun.\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
